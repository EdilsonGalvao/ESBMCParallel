\documentclass[prodmode,acmtrets]{acmsmall} % Aptara syntax

\usepackage{listings} % Codes
%\lstset{
 % language=C,                % choose the language of the code
 % numbers=left,                   % where to put the line-numbers
 % stepnumber=1,                   % the step between two line-numbers.        
 % numbersep=5pt,                  % how far the line-numbers are from the code
 % backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
 % showspaces=false,               % show spaces adding particular underscores
 % showstringspaces=false,         % underline spaces within strings
 % showtabs=false,                 % show tabs within strings adding particular underscores
 % tabsize=2,                      % sets default tabsize to 2 spaces
 % captionpos=b,                   % sets the caption-position to bottom
 % breaklines=true,                % sets automatic line breaking
 % breakatwhitespace=true,         % sets if automatic breaks should only happen at whitespace
 % title=\lstname,                 % show the filename of files included with \lstinputlisting;
%}

\usepackage{mathtools} % Serve para as equacoes

%Montar os Gráficos, cores e divisões.
\usepackage{color}
\usepackage{multirow}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage{booktabs}
\usepackage{tabu,xcolor,colortbl}
\usepackage{rotating}
\usepackage{amsmath,array}  
\usepackage{tabularx} % in the preamble
\usepackage{graphicx} %Imagens

\usepackage{minted}

\newcolumntype{C}[1]{>{\Centering}m{#1}}
\renewcommand\tabularxcolumn[1]{C{#1}}
\usepackage{tabularx,ragged2e,booktabs,caption}

%\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
%\DeclareUnicodeCharacter{FB01}{fi} %Caracter especial

\usepackage{hyphenat}
\hyphenation{par-ti-cu-lar func-tion ef-fect-ive consi-de-red demons-trate se-cond veri-fication covera-ge des-cribe reali-zation opera-tor re-pre-sentation methodo-lo-gy di-gi-tal chara-cteristics granu-lar ge-nerally diago-nal para-meters spe-cification re-presentable me-thods ope-rations sche-dule deve-loped des-cribes diffe-rent mo-dels sa-ving ve-rified proper-ties mini-mum mathe-matical tole-rated limi-ted op-tical net-works semi-conduc-tor go-to-pro-grams }

% Package to generate and customize Algorithm as per ACM style
\usepackage[ruled]{algorithm2e}
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}

%\usepackage[skip=\baselineskip]{caption}
%\captionsetup[lstlisting]{font={small,tt}}


% Metadata Information
\acmVolume{9}
\acmNumber{4}
\acmArticle{39}
\acmYear{2015}
\acmMonth{3}

% Copyright
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

% DOI
\doi{0000001.0000001}

%ISSN
\issn{1234-56789}


% Document starts
\begin{document}


% Page heads
\markboth{A. Trindade et al.}{Multi-Core Model Checking and Maximum Satisfiability Applied to HW/SW Partitioning}

\title{Multi-Core Model Checking and Maximum Satisfiability Applied to Hardware-Software Partitioning}

% Title portion
\author{
Alessandro Trindade
\affil{Federal University of Amazonas}
Hussama Ismail
\affil{Federal University of Amazonas}
Edilson Galv\~ao\
\affil{Federal University of Amazonas}
Renato Degelo\
\affil{Federal University of Amazonas}
Helder Silva
\affil{Federal University of Amazonas}
Lucas Cordeiro\affil{Federal University of Amazonas}
}

% NOTE! Affiliations placed here should be for the institution where the
%       BULK of the research was done. If the author has gone to a new
%       institution, before publication, the (above) affiliation should NOT be changed.
%       The authors 'current' address may be given in the "Author's addresses:" block (below).
%       So for example, Mr. Abdelzaher, the bulk of the research was done at UIUC, and he is
%       currently affiliated with NASA.

\begin{abstract}
We present an alternative approach to solve the hardware and software partitioning problem, which uses Bounded Model Checking (BMC) based on Satisfiability Modulo Theories (SMT) in conjunction with a multi-core support using Open Multi-Processing. In a nutshell, the multi-core SMT-based BMC approach allows initializing many verification instances based on the number of available processing cores. Each instance checks for a different optimum value until the optimization problem is satisfied. We implement our algorithms on top of the Efficient SMT-Based Context-Bounded Model Checker (ESBMC) and also integrate the maximum satisfiability solver $\nu$Z tool into ESBMC. We compare all our approaches to another state-of-the-art optimization tool (Matlab). Experimental results show that there is no single optimization tool to solve all hardware-software partitioning benchmarks; however, Matlab and ESBMC-$\nu$Z are the most efficient ones to solve hardware-software partitioning problems, although multi-core ESBMC had a significant performance improvement in particular cases.
\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10010583.10010682.10010684.10010686</concept_id>
<concept_desc>Hardware~Hardware-software codesign</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010583.10010682.10010712.10010715</concept_id>
<concept_desc>Hardware~Software tools for EDA</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10010940.10010992.10010998.10003791</concept_id>
<concept_desc>Software and its engineering~Model checking</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10010940.10010992.10010998.10010999</concept_id>
<concept_desc>Software and its engineering~Software verification</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Hardware~Hardware-software codesign}
\ccsdesc[500]{Hardware~Software tools for EDA}
\ccsdesc[500]{Software and its engineering~Model checking}
\ccsdesc[500]{Software and its engineering~Software verification}

%
% End generated code
%

%\terms{Design, Algorithms, Performance}

\keywords{hardware-software co-design, hardware-software partitioning, optimization, model checking, multi-core, OpenMP. }

%\acmformat{Gang Zhou, Yafeng Wu, Ting Yan, Tian He, Chengdu Huang, John A. Stankovic,
%and Tarek F. Abdelzaher, 2010. A multifrequency MAC specially
%designed for  wireless sensor network applications.}
% At a minimum you need to supply the author names, year and a title.
% IMPORTANT:
% Full first names whenever they are known, surname last, followed by a period.
% In the case of two authors, 'and' is placed between them.
% In the case of three or more authors, the serial comma is used, that is, all author names
% except the last one but including the penultimate author's name are followed by a comma,
% and then 'and' is placed before the final author's name.
% If only first and middle initials are known, then each initial
% is followed by a period and they are separated by a space.
% The remaining information (journal title, volume, article number, date, etc.) is 'auto-generated'.

\begin{bottomstuff}
A. Trindade, H. Ismail, R. Degelo, E. Galv\~ao \\
Graduate Program in Electrical Engineering, Federal University of Amazonas, Brazil \\
\{alessandro.b.trindade, hussamaismail, rdegelo, esj.galvao\}@gmail.com \\ \\
\and\\ \\
H. Silva and L. Cordeiro \\
Federal University of Amazonas, Brazil\\
prhsilva2012@gmail.com lucascordeiro@ufam.edu.br      \\
\end{bottomstuff}

\maketitle


%---------------------------------
\section{Introduction}
\label{Introduction}
%---------------------------------

Nowadays, with the strong development of embedded systems, the design phase plays an important role. At early stages, the design is split into separated flows: hardware and software. The partitioning decision process, which deals with decisions upon which parts of the application have to be designed in hardware (HW) and which one in software (SW), must be supported by any well-structured methodology. If there is no methodology support, a number of issues, {\it e.g.}, design flow interruptions, redesigns, and undesired iterations may affect the overall development process, the quality, and the life-cycle of the final system.

%In any HW and SW design of complex systems, more time is spent on verification than on construction~\cite{Baier2008}. Formal methods based on model checking offer great potential to obtain a more effective and faster verification in the design process. Software (and systems) may be viewed as mathematical objects with behavior that is, in principle, well determined. This makes it possible to specify software using mathematical logic, which constitutes the intended (correct) behavior. Then, one can try to give a formal proof or otherwise establish that the software meets its specification ~\cite{Clarke2009}. Research in formal methods has led to the development of very promising verification techniques, which facilitate the early detection of errors. Model-based verification techniques use models that describe the possible system behavior in a mathematically precise and unambiguous manner. The system models are accompanied by algorithms that systematically explore all the states of the system model.

Starting at the 1990s, intensive research was performed in HW-SW partitioning, and several approaches proposed, as shown in~\cite{Arato2003} and~\cite{Mann2007}. In~\cite{Trindade2015,Trindade2016} was shown that it is possible to use Bounded Model Checking (BMC) based on Satisfiability Modulo Theories (SMT), implemented in a tool called Efficient SMT-Based Context-Bounded Model Checker (ESBMC), in order to perform HW-SW partitioning in embedded systems. The present work extends those studies since there is a substantial improvement in terms of the SMT-based verification method, which has been extended with a multi-core parallel- and binary-search approaches, as well as, the integration of the Maximum SMT (MaxSMT) solver $\nu$Z into ESBMC, which is a state-of-art optimization tool based on SMT~\cite{Bjorner2015}. 

%Multi-core processors have been used in all segments of industry to implement high-performance computing~\cite{Wu2014}. In particular, hardware platforms, together with multi-processing platforms, have allowed verification algorithms to distribute tasks executions across multiple processors, which generate an increase in performance if compared to single-core solution~\cite{Holzmann11}. However, most algorithms for software verification still disregard the limitations of the CMOS technology and focus their solution on a single-core approach~\cite{Cordeiro2012,Clarke2004,Armando2009,Ganai2006}.

Here, we exploit the availability of multi-core processors; in particular, SMT-based verification methods are applied to the HW-SW partition problem in three different ways using a multi-core ESBMC approach with OpenMP~\cite{Tang2009}: ESBMC-SS using a sequential-search (SS), ESBMC-PS using a parallel-search (PS), and ESBMC-PB using a binary-search (BS). Experimental results are compared to ILP (integral linear programming), GA (generic algorithms) in a multi-core version, and also to $\nu$Z, which supports only a single-core approach~\cite{Bjorner2015}. The ILP and GA algorithms are implemented with the optimization toolbox of Matlab~\cite{TheMathWorks2013}, while $\nu$Z is a built-in tool to the SMT solver Z3. All multi-core ESBMC approaches, together with $\nu$Z, are implemented with the ESBMC tool~\cite{Cordeiro2012}. 

% in which its main function is to check the satisfiability of logical formulas based on objective functions

\textbf{Contributions.} The main contribution of the present study is to describe and evaluate a comprehensive SMT-based BMC approach in a multi-core architecture applied to solve HW-SW optimization problems. Additionally, we integrate the MaxSMT solver $\nu$Z into an off-the-shelf BMC tool, which is typically used for software verification, in order to formulate and solve optimization problems within the logical context of constraints. Experimental results show that multi-core model-checking techniques can be effective, in particular cases, to find the optimal solution of the HW-SW partitioning problem using an SMT-based BMC approach. Although there is no single tool for efficiently solving all HW-SW partitioning problems, we show that the MaxSMT solver $\nu$Z is faster than other state-of-the-art optimization tools for small- and medium-size optimization problems.  To the best of our knowledge, this is the first work to use a multi-core SMT-based verification and a MaxSMT solver to check for HW-SW partitioning problems in embedded systems.

\textbf{Availability of Data and Tools. }Our experiments are based on a set of publicly available benchmarks. All benchmarks, tools, and results of our evaluation are available on a supplementary web page\footnote{http://esbmc.org/}.

This article is organized as follows: Section~\ref{background} gives a background on optimization techniques, $\nu$Z, ESBMC, and OpenMP tools. 
Section~\ref{Mathematical-modeling} describes the informal and formal mathematical modeling. The SMT-based BMC method is presented in Section~\ref{Analysis-of-the-partitioning-problem-using-ESBMC}, and in particular, Section~\ref{Analysis-of-the-partitioning-problem-using-vZ} presents the partitioning model using $\nu$Z. In Section~\ref{Experimental-Evaluation}, we show the experimental results using several embedded systems applications. In Section~\ref{Related-Work}, we discuss the related work and we conclude and describe future work in Section~\ref{Conclusions}.

%----------------------------------------------
\section{Background}
\label{background}
%----------------------------------------------

The HW-SW partitioning problem is typically represented as a set of constraints and an objective function in linear programming. We describe the linear programming problem and present related tools that are used to model and solve the HW-SW partitioning problem.

%----------------------------------------------
\subsection{Optimization}
\label{Optimization}
%----------------------------------------------

Optimization is the act of obtaining the best result ({\it i.e.}, the optimal solution) under given circumstances~\cite{Rao2009}. 
%In the design, construction, and maintenance of any engineering system, engineers have to make many technological and managerial decisions at several stages. The ultimate goal of all such decisions is either to minimize the effort required or to maximize the desired benefit. Because the effort required or the benefit desired in any practical situation can be expressed as a function of certain decision variables, optimization can be defined as the process of finding the conditions that give the maximum or minimum value of a function~\cite{Rao2009}.
There is no single method available for efficiently solving all optimization problems~\cite{Rao2009}. The most well-known technique is linear programming, which is an method applicable for the solution of problems in which the objective function and the constraints appear as linear functions of the decision variables. A particular case of linear programming is ILP, in which the variables can assume just integer values. Eq.~\ref{linear-programming-problem} shows a typical linear programming problem, where $A$ and $b$ are vectors or matrixes that describe the constraints


\begin{equation}
\label{linear-programming-problem}
  minf^t x \: such \; that  = 
  \begin{cases}
    A.x \leq b, \\ 
    Aeq.x = beq, \\ 
    x \geq 0.
  \end{cases}
\end{equation}

\vspace{5 mm}
In some cases, the time to find a solution using ILP is impractical. Even with the use of powerful computers, a problem can take hours before an optimal solution is reached. If the optimization problem is complex, some heuristics can be used to solve the same problem faster, {\it e.g.}, those used in the GA~\cite{Rao2009}. The only drawback is that the found solution may not be the global minimum or maximum. Alternatively, tools such as ESBMC and $\nu$Z can be used to solve optimization problems so that the global minimum or maximum solution is found. The following sections describe the main features of ESBMC and $\nu$Z tools.

%----------------------------------------------
\subsection{Bounded Model Checking with ESBMC}
\label{Bounded-Model-Checking-with-ESBMC}
%----------------------------------------------

Among the recent model checking techniques, there is one that combines model checking with satisﬁability solving. This technique, known as bounded model checking (BMC), does a very fast exploration of the state space, and for some types of problems, it offers large performance improvements over previous approaches, as shown in~\cite{Biere2009}. In particular, BMC based on Boolean Satisfiability (SAT) has been introduced as a complementary technique to binary decision diagrams for alleviating the state explosion problem~\cite{Clarke2001}. 

The basic idea of BMC is to check the negation of a given property at a given depth: given a transition system $M$, a property $\phi$, and a bound $k$, BMC unrolls the system $k$ times and translates it into a verification condition (VC) $\psi$  such that $\psi$ is satisfiable if and only if $\phi$ has a counterexample of depth $k$ or less~\cite{Biere2009}. To cope with increasing software complexity, SMT solvers can be used as back-ends for solving the generated VCs, as shown in~\cite{Cordeiro2012},~\cite{Armando2009},~\cite{Ganai2006}. 

In this study, ESBMC has been used as a BMC tool to solve HW-SW partitioning problems~\cite{Cordeiro2012}. 
In particular, there are two directives in ESBMC that can be used to guide it to solve an optimization problem: ASSUME and ASSERT. The directive ASSUME is responsible for ensuring the compliance of constraints (software costs), and the directive ASSERT controls the halt condition (minimum hardware cost). Then, with some C/C++ code, it is possible to guide ESBMC to solve optimization problems.

%----------------------------------------------
\subsubsection{ESBMC Architecture}
\label{ESBMCArchitecture}
%----------------------------------------------

Fig.~\ref{ESBMC-Architecture} shows the current ESBMC architecture, which consists of the C/C$++$ parser, GOTO Program, GOTO Symex, and SMT solver ~\cite{Ramalho2013}. In particular, ESBMC compiles C/C$++$ code into equivalent GOTO\hyp{}programs ({\it i.e.}, control-flow graphs) using a gcc-compliant style. GOTO-programs can then be processed by the symbolic execution engine, called GOTO Symex, where two recursive functions compute the constraints ($C$) and properties ($P$); finally, it generates two sets of equations ({\it i.e.},\:$C \land \neg P$ ), which are checked for satisfiability by an SMT solver. 

The main factor for ESBMC to use only a single-core relies on its back-end ({\it i.e.}, SMT Solver). Currently, the SMT solvers supported by ESBMC are: Z3~\cite{DeMoura2008}, Boolector~\cite{Brummayer2009}, MathSAT~\cite{Barrett2011}, CVC4~\cite{Bozzano2005}, and Yices~\cite{Dutertre2014}. Most of them do provide neither multi-threaded support nor a parallel version to solve the generated SMT equations.

\begin{figure}[ht]
	\centering
  \includegraphics[scale=1]{figures/esbmc-arch-new.pdf} 
	\caption{ESBMC architecture.}
	\label{ESBMC-Architecture}
\end{figure}

%----------------------------------------------
\subsection{OpenMP}
\label{OpenMP}
%----------------------------------------------

The OpenMP is a set of directives for parallel programming that augments C/C$++$ and Fortran languages~\cite{OpenMP1998}. OpenMP supports most processor architectures and operating systems, {\it e.g.}, Solaris, AIX, HP-UX, Linux, Mac OS X, and Windows. OpenMP uses a portable and very robust model to facilitate the development of parallel applications for a variety of platforms. 

In particular, OpenMP uses the \textit{fork-join} model of parallel execution~\cite{OpenMP1998}. The main thread executes the sequential parts of the program; if a parallel region is encountered, then it forks a team of worker threads. After the parallel region finishes ({\it i.e.}, the API waits until all threads terminate), then the main procedure returns to the single-threaded execution mode~\cite{Wu2014}.

The most basic directive of OpenMP is the ``\textit{\#pragma omp parallel for}'', which parallelizes the enclosing loop; a basic OpenMP example is shown below:

\begin{listing}[H]
\begin{minted}[mathescape,
               linenos,
               numbersep=7pt,
               gobble=0,
               frame=lines,
               framesep=2mm]{matlab}
int k;
#pragma omp parallel for
for (k = 0; k < 10; k++)
  a[k] = 2*k;
\end{minted}
\caption{OpenMP basic Example.}
\label{lst:example}
\end{listing}


\vspace{3 mm}
In the above example, the {\it for} loop is executed in parallel. Each iteration of the loop is executed in a separated thread; and each thread may use an idle processor. There is also a way to specify critical regions, which is a code block that is guaranteed to be executed by a single thread at a time. To create a critical region, the ``\textit{\#pragma omp critical}'' directive is routinely used.

%----------------------------------------------
\subsection{Solving Optimization Problems with $\nu$Z}
\label{Optimization-with-Vz}
%----------------------------------------------

%SMT decides the satisfiability of first-order formulas using a combination of different background theories and thus generalizes propositional satisfiability by supporting uninterpreted functions, linear and nonlinear arithmetic, bitvectors, tuples, arrays, and other decidable first-order theories.

In this study, the SMT solver Z3 is used to check for the satisfiability of formulas generated from the HW-SW partitioning problem~\cite{Bjorner2014}. In particular, we exploit the use of MaxSMT solver $\nu$Z, which is implemented on top of the SMT solver Z3, in order to solve optimization problems; $\nu$Z base function is to optimize objective functions, which formulate optimized criteria, within the logical context of constraints.~$\nu$Z also includes an incremental version of the Maximum Resiliency (MaxRes)~\cite{Federica2008}, in order to achieve Maximum Satisfiability (MaxSAT)~\cite{NarodytskaN} and a Simplex to solve numbers without defined patterns. 

In $\nu$Z, MaxSAT is responsible for the restrictions, while OptSMT optimizes linear arithmetic objectives~\cite{Bjorner2015}. In summary, $\nu$Z provides three main functions that extend Z3 for solving optimization problems, which are: \textit{maximize}, \textit{minimize}, and \textit{assert-soft}.

\begin{itemize}
\item{\textbf{maximize(T)}
this function informs to the solver that a given variable $T$ should be maximized, which includes real, integer, or bit-vector variables.}
\item{\textbf{minimize(T)}
this function informs the solver that a given variable $T$ should be minimized, the accepted types are the same as maximize function.}
\item{\textbf{Assert-Soft F : weight n}
the function \textit{assert-soft} adds a restriction to $F$, which can also add a weight $n$; the default value is $1$.}
\end{itemize}

As an example, one can optimize $\left(K + W\right)$, which is subject to restrictions in $\left(K < 2\right)$ and $\left(W - K < 1\right)$. The expected result of this optimization problem described in the code below is $2$. In fact, the model generated by $\nu$Z shows that $K = 1$ and $W = 1$.

\begin{listing}[H]
\begin{minted}[mathescape,
               linenos,
               numbersep=7pt,
               gobble=0,
               frame=lines,
               framesep=2mm]{c++}
(Declare-Const K Int) 
(Declare-Const W Int)
(assert (< K 2)) 
(assert (< (- W K) 1))
(maximize (+ K W)) 
(check-sat)
\end{minted}
\caption{Example of SMT formula using $\nu$Z.}
\label{vZ}
\end{listing}

\vspace{3 mm}
Fig.~\ref{vZ-Architecture} shows the $\nu$Z architecture. Initially, the SMT formula with objectives is converted to $0-1$ constraints, which leads to a Pseudo-Boolean Optimization (PBO)~\cite{Barth1995,Vasco2005}. If there are many objective functions, $\nu$Z invokes OptSAT for arithmetic or MaxSAT for soft constraints. For constraints using real values, $\nu$Z combines linear arithmetic objectives and uses only one instance of OptSMT. When ``soft constrains'' is used in the mode `` lexicographic'', $\nu$Z invokes MaxSAT using multiple calls for its engine.


\begin{figure}[ht]
	\centering
  \includegraphics[scale=0.3]{figures/vzArch.png} 
	\caption{$\nu$Z architecture extracted from~\cite{Bjorner2015}.}
	\label{vZ-Architecture}
\end{figure}

Z3 is available for platforms in C, C$++$, Java, .NET, and Python; it is possible to download Z3 with $\nu$Z from its github repository~\cite{Z3API}. In this work, the python API is used to formulate HW-SW partitioning problems using the $\nu$Z tool. 

%----------------------------------------------
\section{Mathematical modeling}
\label{Mathematical-modeling}
%----------------------------------------------

The mathematical modeling of the HW-SW partitioning problem was taken from~\cite{Arato2003,Mann2007}.

%----------------------------------------------
\subsection{Informal Model (or Assumptions)}
\label{Informal-Model-or-Assumptions}
%----------------------------------------------

The informal model can be described by five characteristics. First, there is only one software context, {\it i.e.}, there is just one general-purpose processor, and there is only one hardware context. The components of the system must be mapped to either one of these two contexts. Second, the software implementation of a component is associated with a software cost, which is the running time of the component. Third, the hardware implementation of a component has a hardware cost, which can be area, heat dissipation, and energy consumption. Fourth, based on the premise that hardware is significantly faster than software, the running time of the components in hardware is considered as zero. Finally, if two components are mapped to the same context, then there is no overhead of communication between them; otherwise, there is an overhead. The consequence of these assumptions is that scheduling does not need to be addressed in this work. Hardware components do not need scheduling, because the running time is assumed to be zero. Because there is only one processor, software components do not need to be scheduled as well. Therefore, the focus is only on the partitioning problem. That configuration describes a first-generation co-design, where the focus is on bipartitioning ~\cite{Teich2012}.

%----------------------------------------------
\subsection{Formal Model}
\label{Formal-Model}
%----------------------------------------------

The inputs of the problem are: a directed simple graph $ G = (V,E) $, called the task graph of the system, is necessary. The vertices $V = \{V_1,V_2,\dotso,V_n\}$ represent the nodes that are the components of the system that will be partitioned. The edges $E$ represent communication between components. Additionally, each node  $V_i$ has a cost $h(V_i)$ (or $h_i$) of hardware if implemented in hardware and a cost $s(s_i)$ (or $ s_i $) of software if implemented in software. Finally, $c(V_i,V_j)$ represents the communication cost between $V_i$ and $V_j$ if they are implemented in different contexts (hardware or software).

Based on~\cite{Arato2003}, is called a hardware-software partition if it is a bipartition of $V:P = (V_h, V_s)$, where $V_h \cup V_s = V$  and $V_h \cap V_s = 0$. The crossing edges are $E_p = \{(V_i,V_j):V_i \in V_s, V_j \in V_h$ or $v_i \in V_h, v_j \in V_s $. The hardware cost of $P$ is given by Eq.~\ref{hardware-costs}

\begin{align}
\label{hardware-costs}
H_p  &= \Sigma_{v_i \in V_H} h_i
\end{align}

\vspace{3 mm}
\noindent and the software cost of $P$ ({\it i.e.}, software cost of the nodes and the communication cost) is given by Eq.~\ref{software-communication-costs}

%  S_p &= \Sigma_{\left(v_i \;\in\; V_s\right)} s_i + \Sigma_{(v_i,v_j) \in\; %E_p}\; c(V_i, V_j).
\begin{align}
\label{software-communication-costs}
  S_p &= \Sigma_{v_i \in V_s}\:s_i + \Sigma_{(v_i,v_j)\in\:E_p} c(V_i,V_j)
\end{align}

\vspace{3 mm}
Three different optimization and decision problems can be defined. In this paper, the focus is on the case that $ S_0 $ is given, {\it i.e.}, to find a $P$ HW-SW partitioning so that $ S_p \leq S_0 $ and $ H_p $ is minimal, which is thus related to system with hard real-time constraints. Based on Eq.~\ref{linear-programming-problem} and~\ref{software-communication-costs}, the constraints can be reformulated as 

\begin{align}
\label{hw-sw-partitioning}
s\left(1-x\right) + c|E_x| \leq S_0, 
\end{align}

\vspace{3 mm}
\noindent where $x$ represents the decision variable. Concerning the complexity of this problem, Arat\'o {\it et al.}~\cite{Arato2003} demonstrate that it is NP-Hard~\cite{Cormem}.


%----------------------------------------------
\section{Analysis of the partitioning problem}
\label{Analysis-of-the-partitioning-problem-using-ESBMC}
%----------------------------------------------

As computer hardware architecture moves from single- to multi-cores, parallel programming environments should be exploited to take advantage of the ability to run several threads on different processing cores. This section describes the verification algorithm using sequential ESBMC, followed by three multi-core model checking algorithms and the integration of the MaxSMT solver $\nu$Z into ESBMC, in order to speed up the HW-SW partitioning verification. HW-SW partitioning using ILP-based and Genetic Algorithms are also explained.

%----------------------------------------------
\subsection{Partitioning problem using ILP-based,Genetic Algorithms}
\label{ILPGA}
%----------------------------------------------

The ILP and GA were taken from our previous studies~\cite{Trindade2015,Trindade2016}. Both use slack variables in order to be possible to represent constraints and to use commercial tools. However, GA had improvements from the parameters of related studies in order to increase the solution accuracy without producing timeout. The tuning was performed by empirical tests and resulted in changing of three parameters, which are passed to the function \textit{ga} of MATLAB~\cite{TheMathWorks2013}: the population size was set from $300$ to $500$, the Elite count changed from $2$ (default value) to $50$, and the number of generations changed from $100*NumberOfVariables$ (default) to $75$.

%----------------------------------------------
\subsection{Verification Algorithm using Sequential ESBMC}
\label{Verification-Algorithm-using-ESBMC}
%----------------------------------------------

Algorithm~\ref{Pseudocode-describing-ESBMC} shows ESBMC pseudocode with the same constraints and conditions placed on ILP and GA. Two values must be controlled to obtain the results and to perform the optimization. One is the initial software cost, as defined in Section~\ref{Formal-Model}. The other is the halting condition (code violation) that stops the algorithm.

The ESBMC algorithm starts with the declarations of hardware, software, and communication costs. $S_0$ must also be defined, as the transposed incidence matrix and the identity matrix, as typically done in MATLAB. Here, matrices $A$ and $b$ are generated. At that point, the ESBMC algorithm starts to differ from the ILP and GA presented in~\cite{Trindade2015}.

It is possible to inform to ESBMC with which type of values the variables must be tested. Therefore, there is a declaration to populate all decision variables $x$ with non-deterministic Boolean values. Those values that change for each test will generate a possible solution and obey the constraints. If this is achieved, then a feasible solution is found and the ASSUME directive is responsible for ensuring the compliance of those constrains (\textit{i.e.}, $A.x \leq b$).

A loop controls the cost of hardware hint, starting with zero and reaching the maximum value considering the case, where all nodes are partitioned to hardware. To every test performed, the hardware hint is compared to the feasible solution. This is accomplished by an \textit{ASSERT} statement at the end of the algorithm, a predicate that controls the halt condition (a \textit{true-false} statement). If the predicate is \textit{FALSE}, then the optimization is finished, {\it i.e.}, the solution is found. 

The \textit{ASSERT} statement tests the objective function, {\it i.e.}, the hardware cost, and will stop if the hardware cost found is lower than or equal to the optimal solution. However, if \textit{ASSERT} returns a \textit{true} condition, {\it i.e.}, the hardware cost is higher than the optimal solution, then the model-checking algorithm restarts and a new possible solution is generated and tested until the \textit{ASSERT} generates a \textit{false} condition. When the \textit{false} condition happens at verification-time, the execution code is aborted and ESBMC presents the counterexample that caused the condition to be broken. That is the point in which the solution is presented (minimum HW cost).

In the ESBMC algorithm, which is shown below, it is not necessary to add slack variables, because the modulus operation is kept, which reduces the number of variables to be solved. 

\begin{listing}[H]
\begin{minted}[mathescape,
               linenos,
               numbersep=7pt,
               gobble=0,
               frame=lines,
               framesep=2mm]{c++}
 Initialize Variables 
 Declare number of nodes and edges
 Declare hardware cost of each node as array (h)
 Declare software cost of each node as array (s)
 Declare communication cost of each edge (c)
 Declare the initial software cost of (S0)
 Declare transposed incidence matrix graph G (E)
 Define the solutions variable (Xi) as Boolean
 main {
  For TipH = 0 to Hmax Do {
   populate Xi with nondeterministic/test values
   Calculate s(1-x)+c|Ex| and store at variable
   Requirement isued by Assume (Variable <= S0)
   Calculate Hp cost Based on value tested of Xi
   Violation check with Assert(Hp > TipH)
  }
 }
\end{minted}
\caption{Pseudocode describing sequential ESBMC}
\label{Pseudocode-describing-ESBMC}
\end{listing}


%In the multi-core ESBMC algorithm, the only difference is the fact that the value of $ TipH $ and its range is not declared in the algorithm, %as shown in ESBMC Pseudocode. The proposed approach is invoked for each test problem, as follows:
%$ esbmc-parallel <Filename.c> \; <hminvalue> \; <Hmax> $

%Where $ <Filename.c> $ is the optimization problem described in ANSI-C format, $  <hminvalue> $ is the minimum (zero to HW-SW partitioning %problem) and $ <Hmax> $ is the maximum hardware cost for the specified problem.

%Therefore, the algorithm starts different ESBMC instances using different optimization values, in ascending order, for $ Hmax $ in order to %find a violation. If all instances finish and no violation is found, then multi-core ESBMC starts new $ N $ instances. When a violation is %found, it reports time and hardware cost. If multi-core ESBMC tests all the possibilities for the hardware cost and has not found a violation, %then it reports: $ Violation not found $.

%----------------------------------------------
\subsection{Multi-core ESBMC with OpenMP (ESBMC-SS)}
\label{Multi-core-ESBMC-with-OpenMP}
%----------------------------------------------

Typically, ESBMC verification runs are performed only in a single-core. If the processor provides $8$ processing cores, only one is used for the verification and the others remain idle. Thus, there is a significant unused hardware resource during this process. 

To optimize the CPU resources utilization without modifying the underlying SMT solver, the Open Multi-Processing (OpenMP) library~\cite{Dagum1998} is used in this present work as a front-end for ESBMC. Fig.~\ref{ESBMC-Multi-core} shows our first approach called ESBMC sequential-search ``ESBMC-SS''.

\begin{figure}[ht]
	\centering
  \includegraphics[scale=0.9]{figures/esbmc-ss.pdf} 
	\caption{ESBMC-SS approach.}
	\label{ESBMC-Multi-core}
\end{figure}

ESBMC-SS obtains the problem specification represented by a ANSI-C program. The HW-SW partitioning is violated, when the correct optimum value (\textit{TipH}) parameter is reached; ESBMC-SS starts a parallel region with different instances of ESBMC, based on the number of available processing cores. All these ESBMC instances run independently of each other, as shown in Fig.~\ref{ESBMC-Multi-core}. Note that there is no shared-memory (or message-passing) mechanism among threads. In particular, different threads are managed by the OpenMP API, which is responsible for the thread life-cycle: start, running, and dead states, using different values as condition. After executing $N$ instances, if there is no code violation, then ESBMC-SS starts new instances again; this represents a sequential-search on a multi-core environment. During the parallel region execution, if a violation is found in any running thread, then it presents a counterexample with the violation condition and the verification time. If all threads of the batch processing are terminated, then ESBMC-SS finishes its execution.

%----------------------------------------------
\subsection{Multi-core ESBMC with OpenMP using Workers (ESBMC-PS)}
\label{Multi-core-ESBMC-with-OpenMP-using-workers}
%----------------------------------------------

The previous parallelization is implemented by continuously forking ESBMC instances in a sequential manner until the first violation is found. However, since OpenMP only returns from a parallelized loop, when every forked thread finishes, some processing cores could remain idle for some period of time.

\begin{figure}[ht]
	\centering
  \includegraphics[scale=0.9]{figures/esbmc-ps.pdf} 
	\caption{ESBMC-PS approach.}
	\label{ESBMC-Multi-core-Optimized-Sequential-Approach}
\end{figure}

Consequently, the second approach aims to remove the idle time from the parallel loops, by creating workers inside threads so that the next step is immediately executed if there is a processing core available, as shown in Fig.~\ref{ESBMC-Multi-core-Optimized-Sequential-Approach}. This approach could potentially lead to great performance improvements, but as ESBMC checks for each step almost at the same rate, the processor does not remain idle for a longer period and thus there is almost no optimization.

%----------------------------------------------
\subsection{Multi-core ESBMC with OpenMP using Binary Search (ESBMC-PB)}
\label{Multi-core-ESBMC-with-OpenMP-using-Binary-Search}
%----------------------------------------------

The most optimized approach applies a parallelized binary-search to reduce the amount of steps to be executed in order to find the optimal solution. A controller is designed to return the step to be executed so that the number of verification runs are substantially reduced. The parallelized binary search accomplishes this by splitting the domain of possible values into intervals and then by returning the middle of the largest interval so that two new intervals are created.

\begin{figure}[ht]
	\centering
  \includegraphics[scale=0.9]{figures/esbmc-pb.pdf} 
	\caption{ESBMC-PB approach.}
	\label{ESBMC-Binary-Approach}
\end{figure}

As an example, given a problem of domain from $1$ to $20$ (see Fig.~\ref{Binary-Step-Calculation}), we firstly create an initial interval from $1$ to $20$. When the next available core requests a step to be executed, the controller obtains the largest interval, {\it i.e.}, $\left[1,20\right]$, divides it by two, which creates two new intervals ({\it i.e.}, $\left[1,9\right]$ and $\left[11,20\right]$), and returns the middle of the original interval ({\it i.e.}, $10$). The controller also checks whether an interval has less than two elements to avoid creating empty or invalid intervals.

\begin{figure}[ht]
	\centering
  \includegraphics[scale=1.0, height=75px]{figures/Fig4.png}
	\caption{Binary step calculation.}
	\label{Binary-Step-Calculation}
\end{figure}

Note that there might gaps between steps, which are produced by the customized binary-search. For instance, in the example shown in Fig.~\ref{Binary-Step-Calculation}, if step $10$ returns \textit{false}, then one can conclude that all steps after $10$ is \textit{false} as well. However, if the same step $10$ returns \textit{true}, we can assume that all steps before $10$ is \textit{true} as well. As a result, an auxiliary method to remove unnecessary steps is implemented in the controller by removing or shrinking existing intervals. This approach leads to a high impact in the verification time. However, if a step is running and is not needed anymore, the worker kills the forked process and starts a new one.

Algorithm~\ref{Steps-Calculation-using-Intervals} describes how the customized binary search calculates and returns the step to be executed. 
\begin{listing}[H]
\begin{minted}[mathescape,
               linenos,
               numbersep=7pt,
               gobble=0,
               frame=lines,
               framesep=2mm]{c++}
  GetNextStep(){
  int largestChunk = -1;
  chunk largest;
  for each(chunk in chunks){
     if(chunk.right - chunk.left > largestChunk){
           largestChunk = chunk.right - chunk.left;
           largest = chunk;
     }
   }	
   chunks.remove(largest);	
   int median = largest.left + floor((largest.right - largest.left) / 2)
   if(median > 0){
      if(largest.right - largest.left > 1)
         chunks.add(new chunk(largest.left, median - 1));	
      if(largest.right != largest.left)
         chunks.add(new chunk(median + 1, largest.right);
    }
   return median;
 }
\end{minted}
\caption{Steps calculation using intervals.}
\label{Steps-Calculation-using-Intervals}
\end{listing}

Note that Algorithm~\ref{Steps-Calculation-using-Intervals} is called from each worker in order to get the next step to execute if it exists; otherwise, either zero or a negative number is returned.
From lines $4$ to $9$, the algorithm finds the largest interval. Then, from line $10$ the largest interval is removed and the median is calculated in line $11$. After that, two new intervals are created, the left side (in line $14$) and the right side (in line $16$). At the end, the median is returned.

\begin{listing}[H]
\begin{minted}[mathescape,
               linenos,
               numbersep=7pt,
               gobble=0,
               frame=lines,
               framesep=2mm]{c++}
 step = controller.GetNextStep();
 int pid = ExecuteStep(step);
 while(isRunning(pid)){
   if(!controller.isNeeded(step))
    kill(pid);
 }
\end{minted}
\caption{Worker sample.}
\label{worker-sample}
\end{listing}

Algorithm~\ref{worker-sample} describes how the worker starts and monitors ESBMC instances. The algorithm starts by retrieving the step to be executed from the controller (line $1$), then initiates the ESBMC instance and obtains the process \textit{id} from the forked process (line $2$). While the step is being executed, the controller checks whether this step is still needed (line $4$). If not, then the ESBMC instance is killed (line $5$) and the worker is free to initiate another step.

%----------------------------------------------
\subsection{Analysis of the partitioning problem using $\nu$Z (ESBMC-$\nu$Z)}
\label{Analysis-of-the-partitioning-problem-using-vZ}
%----------------------------------------------

Algorithm~\ref{vZ-pseudocode} encodes the objective function and constraints related to the HW-SW partitioning problem using $\nu$Z functions~\cite{Bjorner2014}. A $\nu$Z logical context must firstly be created (line $2$), in order to add constraints and to check whether a given model exists to the set of constraints. Note that the number of nodes and edges, software, hardware, and communications costs as well as the incidence matrix E must also be declared.

The arithmetic expressions from lines $10$ to $12$ represent the constraints described in Eq.~\ref{hw-sw-partitioning}. Here, variable \textit{SC} refers to the software cost, while \textit{CC} denotes the communication cost. In line $12$, the \textit{Fobj} (objective function) is declared, which denotes the product between the hardware cost and the decision variables vector, which contains only Boolean values. \textit{Fobj} should be minimized to obtain the optimal hardware solution. To achieve this, two constraints are imposed to ESBMC-$\nu$Z: the first one refers to the sum of the software and communication costs, where the result should be less than $S_0$; and the second one informs to ESBMC-$\nu$Z that \textit{Fobj} should be minimized. Finally, the model is checked by ESBMC-$\nu$Z and if there is a solution that meets the constraints, then the \textit{Fobj} value is provided.

\begin{listing}[H]
\begin{minted}[mathescape,
               linenos,
               numbersep=7pt,
               gobble=0,
               frame=lines,
               framesep=2mm]{c++}
--Initialize Variables
  Create vZ context 
  Create binary vector (x)
  Declare number of nodes, edges and S0
  Declare hardware cost of each node as array (h) 
  Declare software cost of each node as array (s)
  Declare communication cost of each edge (c)
  Declare transposed incidence matrix graph G (E)
--Arithmetic Expressions
  SC = s(1-x)
  CMC = c*|EX|
  Fobj =  x[i] * h[i]
--Assert Constraints
  Add constraints (SF + CMC <= S0)
  Add constraints to minimize Fobj
  Check Model
  Print Result
\end{minted}
\caption{Pseudocode describing ESBMC-$\nu$Z.}
\label{vZ-pseudocode}
\end{listing}

%----------------------------------------------
\section{Experimental Evaluation}
\label{Experimental-Evaluation}
%----------------------------------------------

This section is split into three parts. The setup is described in Section~\ref{Experimental-Setup}, while Section~\ref{Benchmarks-Description} describes all benchmarks that were used for performing the experimental evaluation. Section~\ref{Experimental-Results} reports a comparison among Matlab~\cite{TheMathWorks2013}, ESBMC-SS, ESBMC-PS, ESBMC-PB, and ESBMC-$\nu$Z using a set of standard HW-SW partitioning benchmarks~\cite{Mann2007}.

%----------------------------------------------
\subsection{Experimental Setup}
\label{Experimental-Setup}
%----------------------------------------------

ESBMC $1$.$24$ running on a $64$-bit Ubuntu $14$.$04$.$1$ LTS operating system was used. A parallel approach of the ESBMC-SS, ESBMC-PS, ESBMC-PB were implemented in C$++$11. Version $2$.$0$.$1$ of Boolector SMT-solver~\cite{Brummayer2009} (freely available) was used as the default solver for ESBMC. ESBMC-$\nu$Z as a built-in tool to Z3 was also used~\cite{Bjorner2014}.  For ILP and GA formulations, MATLAB R$2013$a from MathWorks with Parallel Computing Toolbox was used~\cite{TheMathWorks2013}. MATLAB is a dynamically typed high-level language, known as the state-of-the-art mathematical software~\cite{Tranquillo2011} and is widely used by the engineering community~\cite{Hong2010}.

All experiments were conducted on an otherwise idle Intel Core i$7$-$2600$ ($8$-cores), with $3$.$4$ GHz and $15$ GB of RAM, running Ubuntu $64$-bits. Each time was measured $3$ times (average taken). Based on standard deviation and tolerance interval to each set of time sample, it was obtained a statistical confidence of $91.7$\% to ESBMC (sequential, SS, PB and $\nu$Z), $95.9$\% to ESBMC-PS, and $92.0$\% to ILP and GA. A time out condition (TO) is reached when the verification time is longer than $3600$ seconds. A memory out (MO) occurs when the tool reaches $15$GB of memory. 

%----------------------------------------------
\subsection{Description of Benchmarks}
\label{Benchmarks-Description}
%----------------------------------------------

To perform the experiments, some benchmarks provided by Mann {\it et al.}~\cite{Mann2007} were used, as shown in Table~\ref{tab:Description-of-Benchmarks}. The nodes in the graphs correspond to high-level language instructions. Software and communication costs are time dimensional, and hardware costs represent the occupied area. The first three benchmarks are extracted from MiBench~\cite{Guthaus2001}. The clustering and fuzzy benchmarks are designed from Mann {\it et al.}~\cite{Mann2007} and are significantly large benchmarks. From the same authors, very complex benchmarks to test the limits of the applicability of techniques were used (RC$6$ and Mars).

\begin{minipage}{\linewidth}
\centering
\small
\sffamily\small
\tabulinesep=6pt
\captionof{table}{Description of Benchmarks.} 
\begin{tabular}[c]{m{1.8cm}m{0.9cm}m{0.9cm}m{8.2cm}}
\\
\toprule[1.5pt]
\textbf{Name} & \textbf{Nodes} & \textbf{Edges} & \textbf{Description}\\
\midrule
\\
\verb|CRC32| & \verb|25| & \verb|32| & \normalsize 32-bit cyclic redundancy check ~\cite{Guthaus2001}\\
\\
\hline
\\
\verb|Patricia| & \verb|21| & \verb|48| & \rmfamily Routine to insert values in Patricia Tree ~\cite{Guthaus2001}\\
\\
\hline
\\
\verb|Dijkstra| & \verb|26| & \verb|69| & \rmfamily Computer shortest paths in a graph ~\cite{Guthaus2001}\\
\\
\hline
\\
\verb|Clustering| & \verb|150| & \verb|331| & \rmfamily Image segmentation algorithm in a medical application\\
\\
\hline
\\
\verb|RC6| & \verb|329| & \verb|448| & \rmfamily RC6 cryptography graph algorithm\\
\\
\hline
\\
\verb|Fuzzy| & \verb|261| & \verb|422| & \rmfamily Clustering algorithm based on fuzzy logic\\
\\
\hline
\\
\verb|Mars| & \verb|417| & \verb|600| & \rmfamily MARS cipher from IBM algorithm\\
\\
\bottomrule[1.5pt]
\label{tab:Description-of-Benchmarks} 
\end{tabular}\par
\bigskip
\end{minipage}


%\begin{table}[h]
%\centering
%\caption {Description of Benchmarks.}
%\small
%\sffamily\small
%\tabulinesep=6pt


%\label{Description-of-Benchmarks}
%\end{table}

%----------------------------------------------
\subsection{Experimental Results}
\label{Experimental-Results}
%----------------------------------------------

Table~\ref{Experimental-results-of-the-complex-benchmarks} shows the experimental results using Matlab (ILP and GA) and ESBMC (ESBMC\hyp{}MC, ESBMC\hyp{}PS, ESBMC\hyp{}PB, ESBMC\hyp{}$\nu$Z) tools.

There is no single tool for efficiently solving all HW-SW partitioning benchmarks. In particular, the best (proposed) solution is ESBMC-$\nu$Z, which solves $4$ out of $7$ benchmarks, but it does not find the optimal solution for the RC$6$ benchmark; however, ESBMC-$\nu$Z is faster than ILP in all supported benchmarks ({\it i.e.}, CRC$32$, Patricia, Dijkstra, Clustering), but it returns three TOs (time-outs) related to RC6, Fuzzy and Mars benchmarks.

In contrast to ESBMC-$\nu$Z, ILP solves $5$ out of $7$ benchmarks. When ILP produces a result, it provides the optimal solution. On the one hand, ILP execution time is slower than $\nu$Z in all benchmarks, which are supported by $\nu$Z. On the other hand, ILP is faster than ESBMC-SS, ESBMC-PS, and ESBMC-PB in all benchmarks, except for the clustering.

Note further that all multi-core ESBMC implementations produce better results than the sequential one. In particular, ESBMC-PB implementation outperforms all other multi-core ESBMC approaches, where its performance improves as the number of nodes and edges increase. One notable case is the clustering benchmark, when verified by ESBMC-PB, it executes $3$ times faster than ILP and $1$.$89$ times slower than ESBMC-$\nu$Z. However, when the amount of nodes is around $30$, ESBMC-PB does not outperform ESBMC-$\nu$Z and ILP tools. When analyzing all benchmarks, ESBMC-PB produces TO for RC$6$, Fuzzy, and Mars; however, the results are still promising if we take into consideration that $\nu$Z and Matlab are state-of-the-art tools with respect to optimization problems.

%When ESBMC-$\nu$Z explores a small amount of nodes, it is typically $30$ times faster ({\it e.g.}, CRC$32$) than ESBMC-PB and for intermediate nodes (around $150$ nodes), this performance improvement decreases to $1$.$8$ ({\it e.g.}, Clustering). 

The only technique that is able to solve all benchmarks is GA; however, its precision is not satisfactory since it produces an error rate between $-37.6$\% and $29.0$\%.

Note that RC$6$ produced time out for all implementations of ESBMC; $\nu$Z e GA did not produce the correct answer, and ILP solves correctly all benchmarks, except for Fuzzy, which produced time-outs and memory-outs in all tools that aim to find the exact solution. No tool was capable to solve Mars in less than $3600$ seconds, while GA solved all benchmarks, but mostly incorrectly.

The clustering benchmark seems to be the limit to test the ESBMC (described) implementations; note, however, that more than $150$ nodes lead to TO and MO. ILP shows robustness and produces results even for a high number of nodes and edges, but limited to $329$ nodes.

\begin{table*}[t]
  \centering
  \caption{Experimental results of the HW-SW partitioning benchmarks.}  
  \begin{tabular}{*{9}{cc|c|c|c|c|c|c|c}}
\\
 &  & \rotatebox{90}{\textbf{\normalsize{CRC32}}} & \rotatebox{90}{\textbf{\normalsize{Patricia}}} & \rotatebox{90}{\textbf{\normalsize{Dijkstra}}} & \rotatebox{90}{\textbf{\normalsize{Clustering}}} & \rotatebox{90}{\textbf{\normalsize{RC6}}} & \rotatebox{90}{\textbf{\normalsize{Fuzzy}}} & \rotatebox{90}{\textbf{\normalsize{Mars}}} \\[0.15cm]
\cmidrule(r){3-9}

&\textbf{\normalsize{Nodes}} &\normalsize{25} & \normalsize{21} & \normalsize{26} & \normalsize{150} & \normalsize{329} & \normalsize{261} & \normalsize{417}\\
&\textbf{\normalsize{Edges}} &\normalsize{32} & \normalsize{48} & \normalsize{69} & \normalsize{331} & \normalsize{448} & \normalsize{442} & \normalsize{600}\\
&\textbf{\normalsize{S0}} &\normalsize{20} & \normalsize{10} & \normalsize{20} & \normalsize{50} & \normalsize{600} & \normalsize{4578} & \normalsize{300} \\

%EXACT Solution
\bottomrule[1.5pt]
\rowcolors{1}{}{lightgray}

\multirow{4}{*}{\textbf{\normalsize{Exact Solution}}}
& & & & & & & & & \\
&  \normalsize{Hp}   &  \normalsize{15}   &  \normalsize{47}   &  \normalsize{31}   &  \normalsize{241} &  \normalsize{692} &  \normalsize{13820}   &  \normalsize{876} \\
&  \normalsize{Sp}   &  \normalsize{19}   &  \normalsize{4}   &  \normalsize{19}   &  \normalsize{46}   &  \normalsize{533}    &  \normalsize{4231}   &  \normalsize{297}  \\
& & & & & & & & & \\

\bottomrule[1.5pt]
%ILP
\multirow{4}{*}{\textbf{\normalsize{ILP}}}
& & & & & & & & & \\
&  \normalsize{T(s)}   &  \normalsize{1.6}   &  \normalsize{1.3}  &  \normalsize{1.6}   &  \normalsize{648.9}   &  \normalsize{1806.2}    &  \normalsize{TO}   &  \normalsize{TO}  \\
&  \normalsize{Hp}   &  \normalsize{15}  &  \normalsize{47}   &  \normalsize{31}   &  \normalsize{241}   &  \normalsize{692}    &  -   &  -  \\
& & & & & & & & & \\
\hline

%GA
\multirow{4}{*}{\textbf{\normalsize{{GA}}}}
& & & & & & & & & \\
&  \normalsize{T(s)}   &  \normalsize{6.7}   &  \normalsize{7.4}   &  \normalsize{8.8}   &  \normalsize{340.4}   &  \normalsize{2050.0}    &  \normalsize{1371.9}   &  \normalsize{TO}  \\
&  \normalsize{Error \%}   &  \normalsize{13.3}   &  \normalsize{0.0}   &  \normalsize{29.0}   &  \normalsize{1.7}   &  \normalsize{-6.5}    &  \normalsize{-37.6}   &  -  \\
& & & & & & & & & \\
\hline

%ESBMC
\multirow{4}{*}{\textbf{\normalsize{{ESBMC}}}}
& & & & & & & & & \\
&  \normalsize{T(s)}   & \normalsize{30.3}   &  \normalsize{313.7}   &  \normalsize{324.7}   &  \normalsize{MO}   & \normalsize{MO}    &  \normalsize{MO}   &  \normalsize{MO } \\
&  \normalsize{Hp}   &  \normalsize{15}   &  \normalsize{47}   &  \normalsize{31}   &  -   &  -    &  -   &  -  \\
& & & & & & & & & \\
\hline

%MultiCore ESBMC
\multirow{4}{*}{\textbf{\normalsize{{ESBMC-SS}}}}
& & & & & & & & & \\
&  \normalsize{T(s)}   & \normalsize{2.2}  &  \normalsize{5.8}   &  \normalsize{7.0}  &  \normalsize{1609.3}   &  \normalsize{TO}    &  \normalsize{TO}   &  \normalsize{TO}  \\
&  \normalsize{Hp}   &  \normalsize{15}   &  \normalsize{47}   &  \normalsize{31 }  &  \normalsize{241 }  &  -    &  -   &  -  \\
& & & & & & & & & \\
\hline

%ESBMC Parallel sequential
\multirow{4}{*}{\textbf{\normalsize{ESBMC-PS}}}
& & & & & & & & & \\
&  \normalsize{T(s)} &  \normalsize{3.7} &  \normalsize{10.0}   &  \normalsize{12.0}   &  \normalsize{2468.0}   &  \normalsize{TO}    &  \normalsize{TO}   &  \normalsize{TO}  \\
&  \normalsize{Hp}   &  \normalsize{15}   &  \normalsize{47}   &  \normalsize{31}   &  \normalsize{241}   &  -    &  -   &  -  \\
& & & & & & & & & \\
\hline

%ESBMC Parallel Binary
\multirow{4}{*}{\textbf{\normalsize{{ESBMC-PB}}}}
& & & & & & & & & \\
&  \normalsize{T(s)}   &  \normalsize{4.3}   & \normalsize{4.7}   &  \normalsize{6.3}   &  \normalsize{218.7}   &  \normalsize{TO}    & \normalsize{TO}   & \normalsize{TO} \\
&  \normalsize{Hp}   &  \normalsize{15}   &  \normalsize{47}   &  \normalsize{38}   &  \normalsize{241}   &  -    &  -   &  -  \\
& & & & & & & & & \\
\hline

%vZ
\multirow{4}{*}{\textbf{\normalsize{{ESBMC-$\nu$Z}}}}
& & & & & & & & & \\
&  \normalsize{T(s)}   &  \normalsize{0.3}   & \normalsize{0.3}   &  \normalsize{0.7}   &  \normalsize{86.4}   &  \normalsize{TO}    &  \normalsize{TO}   &  \normalsize{TO } \\
&  \normalsize{Hp}   &  \normalsize{15}   &  \normalsize{47}   &  \normalsize{31}   &  \normalsize{241}   &  -    &  -   &  -  \\
& & & & & & & & & \\

\bottomrule[1.5pt]
\end{tabular}
\label{Experimental-results-of-the-complex-benchmarks}
\end{table*}

%----------------------------------------------
\section{Related Work}
\label{Related-Work}
%----------------------------------------------

Since the second half of the first decade of 2000s, three main paths have been tracked to improve or to present alternative solutions to the optimization of HW-SW partitioning, {\it i.e.}, to find the exact solution~\cite{Mann2007}, to use heuristics to speed up performance time~\cite{Arato2003}, and hybrid ones~\cite{Arato2005}.

In the first group, the exact solution to the HW-SW partitioning problem is found. The use of SMT-based verification presented in this paper can be grouped into this category, because the exact solution is found with the given algorithms. The difference is based only on the technique chosen to solve the problem.
Another path followed in past initiatives and which has had more studies is the creation of heuristics to speed up the running time of the solution. The difference of this kind of solution to SMT-based verification and maximum satisfiability is based on two facts: all ESBMC implementations guarantee to find the exact solution, but heuristics are faster, when the complexity is greater.

Finally, there are approaches that mixes heuristics with exact solution tools. The idea is to use a heuristic to speed up some phase of an exact solution tool. It worth mentioning that the final solution is not necessarily an optimal global solution. Only the SMT-based verification is guaranteed to find the exact solution, but hybrid algorithms are faster when complexity rises.

In terms of SMT-based verification, most related studies are restricted to present the model, its modification to programming languages ({\it e.g.}, C/C++ and Java), and the application to multi-thread algorithms or to embedded systems to check for program correctness. In~\cite{Ramalho2013} it presents a bounded model checker for C++ programs, which is an evolution of dealing with C programs and~\cite{Cordeiro2012} uses ESBMC for embedded ANSI-C software. In~\cite{Trindade2015} and~\cite{Trindade2016} it was proven that it is possible to use ESBMC to solve HW-SW partitioning in a single- and multi-core way. There are related studies focused on decreasing the verification time of model checkers by applying Swarm Verification ~\cite{Holzmann2011}, and modifications of internal search engines to add support for parallelism ~\cite{Holzmann2012}, but there is still the need for initiatives related to parallel SMT solvers ~\cite{Wintersteiger2009}. 

Recently, the SMT solver Z3 has been extended to pose and solve optimization problems modulo theories ~\cite{Bjorner2015}. In particular, 
$\nu$Z tool offers substantial performance improvement in optimization problems~\cite{Bjorner2014,Bjorner2015}. As an application example, Pavlinovic {\it et al.}~\cite{Pavlinovic2015} propose an approach which considers all possible compiler error sources for statically typed functional programming languages and reports the most useful one subject to some usefulness criterion. The authors formulate this approach as an optimization problem related to SMT and use $\nu$Z to compute an optimal error source in a given ill-typed program. The approach described by Pavlinovic {\it et al.}, which uses MaxSMT solver $\nu$Z, shows a significant performance improvement if compared to previous SMT encodings and localization algorithms.

The problem addressed in this present paper uses a single objective function for minimization. In~\cite{Patrick2015}, OptiMathSAT and $\nu$Z are compared for software optimization problems. OptiMathSAT, using multiple objective functions, works better than $\nu$Z; however, for problems with a single objective function, the performance of $\nu$Z is better than OptiMathSAT.

%----------------------------------------------
\section{Conclusions}
\label{Conclusions}
%----------------------------------------------

We presented five approaches to solve the HW-SW partitioning problem and compared them to other state-of-the-art techniques. Experimental results showed that for a number of nodes larger than $300$, the best solution for the HW-SW partitioning problem is ILP. Below that, the best solution turns out to be ESBMC-$\nu$Z since its execution time is faster and notorious. ESBMC-PB is a viable alternative for a number of nodes lower than $150$. GA had an intermediate result in terms of performance, but the error presented from exact solution made it not acceptable to that kind of application. 

If considering off-the-shelf tools, as MATLAB to ILP and GA, the coding is simpler. However, ESBMC and $\nu$Z have BSD-Style and MIT licenses, respectively and can be downloaded and used for free. Experimental results also pointed to an improvement of ESBMC, when using a parallel approach. In particular, all three parallel approaches described in this paper produced expressive results. The fastest ESBMC approaches is ESBMC-PB, which produces good results for an intermediate amount of edges and nodes. Thus, considering that nowadays processors have more and more cores, when modeling the problem, it is possible to consider multi-core model checking as an alternative to solve the HW-SW partitioning problem. 

Finally, there is an issue about $150$ nodes problem, since it seems to be the limit of multi-core ESBMC. However, it really depends on the modeling granularity of the problem. Some researchers propose fine-grained models, in which each instruction can be mapped to either HW or SW. This may lead to thousands of nodes or even more. Others defend coarse-grained models, where decisions are made for larger components, thus even complex systems may consist of just some dozens of nodes to partition. In principle, a fine-grained approach may allow to obtain better partitions, but at the cost of an exponential increase of the search space size. In future work, we will address improvements in ESBMC to remove the parallel layer on top of ESBMC and implement it during symbolic execution so that we can optimize the overall verification time.


%%%%%%%%%%%%%%%%%%%%%%%%%%
% ---- Bibliography ---- %
%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{ACM-Reference-Format-Journals}
\bibliography{Ref.bib}

\end{document}
